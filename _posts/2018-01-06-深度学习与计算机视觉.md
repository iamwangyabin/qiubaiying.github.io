---
layout:     post
title:      深度学习与计算机视觉
subtitle:   读书笔记
date:       2018-06-05
author:     WYB
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - CV
---

# 1、引言
没啥可说的……几分钟过了一遍。
# 2、基础数学知识
## 2.1 线性变换和非线性变换
### 2.1.1 线性变换意义
线性变换就是有如下性质的函数T

```math
T(u+v)=T(u)+T(v)

T(av)=aT(v)
```
不过我们一般用的线性变换是矩阵乘法

### 2.1.2
矩阵乘法能旋转（乘以三角函数）还能缩放（乘以倍数）
### 2.1.3 点积和投影
内积就是

```math
u*v=u_1v_1+……+u_nv_n
```
内积是点积的推广，点积就是欧几里得空间的标准内积。  
**两个向量点积的几何意义：**  
**一个向量u在另一个向量v方向上的分量的长度，和v的长度相乘得到的值。** 这个u在v上的长度叫做投影。  
通过推导可以知道两个向量的夹角cos：  

```math
cos(\theta)=\frac{uv}{|u||v|}
```
### 2.1.4 矩阵乘法的几何意义
### 2.1.5 本征向量和本征值
就是特征值  
本征值的几何含义：  
变换会将对应本征向量方向上的向量进行缩放，缩放的倍数就是本征值。  
正定矩阵：  
就是一个向量经过正定变换后和自身点积大于零。也就是正定矩阵对应的变换不会把变换后的向量bian'dao


### 3
神经元数目对应分类界面的线段数量，神经元越多边界就越复杂。  
神经元数目对应非线性变换后空间的维度。

### 4
卷积核就是找到图像中和自身纹理最相似的部分。
#### 4.1.7 池化
池化就是对统计信息的提取  
池化引入了不变性，在池化区域的任何位移不会对结果产生影响，相当于模拟了视野感